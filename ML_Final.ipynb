{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T21:01:06.817083Z",
     "start_time": "2019-12-19T21:01:04.323926Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\russe\\\\Desktop\\\\ML1\\\\final project'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T21:01:07.439569Z",
     "start_time": "2019-12-19T21:01:07.435594Z"
    }
   },
   "outputs": [],
   "source": [
    "#change working directory\n",
    "os.chdir('C:\\\\Users\\\\russe\\\\Desktop\\\\ML1\\\\final project')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T21:01:25.592482Z",
     "start_time": "2019-12-19T21:01:12.809669Z"
    }
   },
   "outputs": [],
   "source": [
    "#Read data\n",
    "#train_000_01.csv and val_000_01.csv are the data sets ........[OS]\n",
    "\n",
    "#Import train datasets\n",
    "train_000_01=pd.read_csv(\"train_000_01.csv\")\n",
    "#Import Validation datasets\n",
    "val_000_01=pd.read_csv(\"val_000_01.csv\") \n",
    "val_000_02=pd.read_csv('val_000_02.csv')\n",
    "val_000_03=pd.read_csv(\"val_000_03.csv\")\n",
    "test_000_04=pd.read_csv('val_000_04.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Description [OS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distribution of each variables\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#c=''\n",
    "count = train_000[c].value_counts()\n",
    "sns.set(style=\"darkgrid\")\n",
    "sns.barplot(count.index, count.values, alpha=0.9)\n",
    "plt.title(c)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To be added later...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T21:01:51.773350Z",
     "start_time": "2019-12-19T21:01:51.682579Z"
    }
   },
   "outputs": [],
   "source": [
    "#For the variable hour, which is the date and hour when the ad was displayed.\n",
    "#We would like to get the information of hour since people tend to click on advertisement on specific time period \n",
    "train_000_01.hour=train_000_01.hour % 100\n",
    "val_000_01.hour=val_000_01.hour % 100\n",
    "val_000_02.hour=val_000_02.hour % 100\n",
    "val_000_03.hour=val_000_03.hour % 100\n",
    "test_000_04.hour=test_000_04.hour % 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T21:02:29.474971Z",
     "start_time": "2019-12-19T21:02:29.205104Z"
    }
   },
   "outputs": [],
   "source": [
    "#Define x-variables and y-variable in train and validation data set\n",
    "feature=range(3,25,1)\n",
    "X_train=train_000_01.iloc[:,feature]\n",
    "y_train=train_000_01.iloc[:,2]\n",
    "X_val=val_000_01.iloc[:,feature]\n",
    "y_val=val_000_01.iloc[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T21:03:11.987796Z",
     "start_time": "2019-12-19T21:02:33.773779Z"
    }
   },
   "outputs": [],
   "source": [
    "#Feature Hashing\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "X_train_hash = X_train.copy()\n",
    "X_val_hash = X_val.copy()\n",
    "for i in range(X_train_hash.shape[1]):\n",
    "    X_train_hash.iloc[:,i]=X_train_hash.iloc[:,i].astype('str')\n",
    "for i in range(X_val_hash.shape[1]):\n",
    "    X_val_hash.iloc[:,i]=X_val_hash.iloc[:,i].astype('str')\n",
    "\n",
    "#encoding hashing\n",
    "h = FeatureHasher(n_features=10000,input_type=\"string\")\n",
    "X_train_hash = h.transform(X_train_hash.values)\n",
    "X_val_hash = h.transform(X_val_hash.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T21:07:58.256640Z",
     "start_time": "2019-12-19T21:07:54.549509Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Import Neccessary Packages\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, KFold, cross_val_score\n",
    "import keras \n",
    "import random as rn\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import lightgbm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup Cross-Validation for parameter tuning\n",
    "inner_cv = KFold(n_splits=5, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logsitic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T19:42:50.575212Z",
     "start_time": "2019-12-19T19:39:14.845978Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41071404860847205 0.001\n",
      "0.40299012543607277 0.01\n",
      "0.4022408982723193 0.1\n",
      "0.4043896534497718 1\n",
      "0.40493106346280516 10\n",
      "0.4049826657485176 100\n"
     ]
    }
   ],
   "source": [
    "#We used for loop to do parameter tuning for logistic regression\n",
    "#using l2 norm penalty\n",
    "C_param_range = [0.001,0.01,0.1,1,10,100]\n",
    "for i in C_param_range:\n",
    "    lr = LogisticRegression(penalty = 'l2', C = i,random_state = 0)\n",
    "    lr.fit(X_train_hash,y_train)\n",
    "    y_pred = lr.predict_proba(X_val_hash)\n",
    "    print(log_loss(y_val,y_pred),i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T20:17:48.025030Z",
     "start_time": "2019-12-19T19:43:40.166247Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4254182087876406 0.001\n",
      "0.4082307798252424 0.01\n",
      "0.40178890447059795 0.1\n",
      "0.4035055169832538 1\n",
      "0.40481817130573855 10\n",
      "0.40497855199318367 100\n"
     ]
    }
   ],
   "source": [
    "#We used for loop to do parameter tuning for logistic regression\n",
    "#using l1 norm penalty\n",
    "C_param_range = [0.001,0.01,0.1,1,10,100]\n",
    "for i in C_param_range:\n",
    "    lr = LogisticRegression(penalty = 'l1', C = i,random_state = 0)\n",
    "    lr.fit(X_train_hash,y_train)\n",
    "    y_pred = lr.predict_proba(X_val_hash)\n",
    "    print(log_loss(y_val,y_pred),i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T21:20:21.813405Z",
     "start_time": "2019-12-19T21:14:56.617010Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.403036153071102\n"
     ]
    }
   ],
   "source": [
    "#According to the parameter tuning result, the best C = 0.1\n",
    "#Test the generalized performance on the testing set\n",
    "y_test=test_000_04.iloc[:,2]\n",
    "X_test=test_000_04.iloc[:,feature]\n",
    "#hasing\n",
    "X_test_hash = X_test.copy()\n",
    "for i in range(X_test_hash.shape[1]):\n",
    "    X_test_hash.iloc[:,i]=X_test_hash.iloc[:,i].astype('str')\n",
    "h = FeatureHasher(n_features=10000,input_type=\"string\")\n",
    "X_test_hash = h.transform(X_test_hash.values)\n",
    "    \n",
    "l = LogisticRegression(penalty = 'l1', C = 0.1,random_state = 0)\n",
    "l.fit(X_train_hash,y_train)\n",
    "y_pred_test_logit = l.predict_proba(X_test_hash)\n",
    "\n",
    "print(log_loss(y_test,y_pred_test_logit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameter tuning \n",
    "np.random.seed(42)\n",
    "\n",
    "gs_lr = GridSearchCV(estimator=LogisticRegression(random_state=42,solver='liblinear'),\n",
    "                  param_grid=[{'C': [0.00001, 0.0001, 0.001, 0.01, 0.1 ,1 ,10 ,100, 1000, 10000, 100000],'penalty':['l1','l2']}],\n",
    "                  scoring='neg_log_loss',\n",
    "                  cv=inner_cv)\n",
    "\n",
    "gs_lr = gs_lr.fit(X_train_hash,y_train)\n",
    "print(\"Logistic Regression Parameter Tuning\")\n",
    "print(\"Non-nested CV Log-Loss: \", gs_lr.best_score_)\n",
    "print(\"Optimal Parameter: \", gs_lr.best_params_)\n",
    "print(\"Optimal Estimator: \", gs_lr.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Method using Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T21:05:05.184682Z",
     "start_time": "2019-12-19T21:04:57.043724Z"
    }
   },
   "outputs": [],
   "source": [
    "#Import other three train datasets to train logistic regression model\n",
    "y_train_01=y_train\n",
    "\n",
    "train_000_02=pd.read_csv(\"val_000_01.csv\")\n",
    "train_000_02.hour=train_000_02.hour % 100\n",
    "X_train_02=train_000_02.iloc[:,feature]\n",
    "y_train_02=train_000_02.iloc[:,1]\n",
    "\n",
    "train_000_03=pd.read_csv(\"val_000_02.csv\")\n",
    "X_train_03=train_000_03.iloc[:,feature]\n",
    "y_train_03=train_000_03.iloc[:,1]\n",
    "\n",
    "train_000_04=pd.read_csv(\"val_000_03.csv\")\n",
    "X_train_04=train_000_04.iloc[:,feature]\n",
    "y_train_04=train_000_04.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T21:06:07.599280Z",
     "start_time": "2019-12-19T21:05:14.641869Z"
    }
   },
   "outputs": [],
   "source": [
    "#Repeat hashing for these three new train datasets\n",
    "X_train_hash_01=X_train_hash\n",
    "\n",
    "X_train_hash_02 = X_train_02.copy()\n",
    "for i in range(X_train_hash_02.shape[1]):\n",
    "    X_train_hash_02.iloc[:,i]=X_train_hash_02.iloc[:,i].astype('str')\n",
    "X_train_hash_02 = h.transform(X_train_hash_02.values)\n",
    "\n",
    "X_train_hash_03 = X_train_03.copy()\n",
    "for i in range(X_train_hash_03.shape[1]):\n",
    "    X_train_hash_03.iloc[:,i]=X_train_hash_03.iloc[:,i].astype('str')\n",
    "X_train_hash_03 = h.transform(X_train_hash_03.values)\n",
    "\n",
    "X_train_hash_04 = X_train_04.copy()\n",
    "for i in range(X_train_hash_04.shape[1]):\n",
    "    X_train_hash_04.iloc[:,i]=X_train_hash_04.iloc[:,i].astype('str')\n",
    "X_train_hash_04 = h.transform(X_train_hash_04.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T21:09:16.298739Z",
     "start_time": "2019-12-19T21:09:16.295573Z"
    }
   },
   "outputs": [],
   "source": [
    "l = LogisticRegression(penalty = 'l1', C = 0.1,random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-12-19T21:20:44.709Z"
    }
   },
   "outputs": [],
   "source": [
    "#Fit these three train datasets and make predictions based on validation dataset\n",
    "l.fit(X_train_hash_01,y_train_01)\n",
    "y_pred_02 = l.predict_proba(X_test_hash)\n",
    "l.fit(X_train_hash_02,y_train_02)\n",
    "y_pred_02 = l.predict_proba(X_test_hash)\n",
    "l.fit(X_train_hash_03,y_train_03)\n",
    "y_pred_03 = l.predict_proba(X_test_hash)\n",
    "l.fit(X_train_hash_04,y_train_04)\n",
    "y_pred_04 = l.predict_proba(X_test_hash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40650008460285525\n"
     ]
    }
   ],
   "source": [
    "#Calculate the average performance\n",
    "y_pred_avg=(y_pred_01+y_pred_02+y_pred_03+y_pred_04)/4\n",
    "\n",
    "print(log_loss(y_test,y_pred_avg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performance of Model with best parameters\n",
    "r = RandomForestClassifier()\n",
    "r.fit(X_train_hash,y_train)\n",
    "#predicting on the validation set\n",
    "y_pred_r = r.predict_proba(X_val_hash)\n",
    "print(log_loss(y_val,y_pred_r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid search parameter tuning\n",
    "np.random.seed(42)\n",
    "\n",
    "gs_rf = GridSearchCV(estimator=RandomForestClassifier(random_state=42),\n",
    "                  param_grid=[{'max_depth': [1, 2, 3, 4, 5, None],'criterion':['gini','entropy'],'n_estimators':[10,50,100]}],\n",
    "                  scoring='neg_log_loss',\n",
    "                  cv=inner_cv)\n",
    "\n",
    "gs_rf = gs_rf.fit(X_train_hash,y_train)\n",
    "print(\"Random Forest Parameter Tuning\")\n",
    "print(\"Non-nested CV Log-Loss: \", gs_rf.best_score_)\n",
    "print(\"Optimal Parameter: \", gs_rf.best_params_)\n",
    "print(\"Optimal Estimator: \", gs_rf.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Datasets preparation for Neural Network\n",
    "\n",
    "#Feature Hashing using 500 n_features\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "X_train_hash = X_train.copy()\n",
    "X_val_hash = X_val.copy()\n",
    "for i in range(X_train_hash.shape[1]):\n",
    "    X_train_hash.iloc[:,i]=X_train_hash.iloc[:,i].astype('str')\n",
    "for i in range(X_val_hash.shape[1]):\n",
    "    X_val_hash.iloc[:,i]=X_val_hash.iloc[:,i].astype('str')\n",
    "\n",
    "#encoding hashing\n",
    "h = FeatureHasher(n_features=500,input_type=\"string\")\n",
    "X_train_hash = h.transform(X_train_hash.values)\n",
    "X_val_hash = h.transform(X_val_hash.values)\n",
    "\n",
    "#convert into array\n",
    "YTr = np.array(y_train)\n",
    "XTr = x_train_hash.toarray()\n",
    "\n",
    "YVal = np.array(y_val)\n",
    "XVal = x_val_hash.toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rescale\n",
    "XTrRsc = (XTr - XTr.min(axis=0))/XTr.ptp(axis=0)\n",
    "XTrRsc.shape\n",
    "XTrRsc.min(axis=0)\n",
    "XTrRsc.max(axis=0)\n",
    "\n",
    "# Note YTr does not need to be rescaled since it is binary\n",
    "\n",
    "#Rescale Validation Data. Really should use Training parameters to rescale.\n",
    "XValRsc = (XVal - XTr.min(axis=0))/XTr.ptp(axis=0)\n",
    "XValRsc.shape\n",
    "XValRsc.min(axis=0)\n",
    "XValRsc.max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BatchSize=250\n",
    "Optimizer=optimizers.RMSprop(lr=0.01)\n",
    "\n",
    "def SetTheSeed(Seed):\n",
    "    np.random.seed(Seed)\n",
    "    rn.seed(Seed)\n",
    "    session_conf = tf.ConfigProto(intra_op_parallelism_threads=1,inter_op_parallelism_threads=1)\n",
    "\n",
    "    tf.set_random_seed(Seed)\n",
    "\n",
    "    sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "    K.set_session(sess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NN MODEL 1 sigmoid activation function\n",
    "\n",
    "NEpochs = 1000\n",
    "BCNN = Sequential()\n",
    "\n",
    "BCNN.add(Dense(units=4,input_shape=(XTrRsc.shape[1],),activation=\"relu\",use_bias=True))\n",
    "BCNN.add(Dense(units=4,activation=\"relu\",use_bias=True))\n",
    "BCNN.add(Dense(units=4,activation=\"relu\",use_bias=True))\n",
    "BCNN.add(Dense(units=4,activation=\"relu\",use_bias=True))\n",
    "BCNN.add(Dense(units=1,activation=\"sigmoid\",use_bias=True))\n",
    "\n",
    "BCNN.compile(loss='binary_crossentropy', optimizer=Optimizer,metrics=['binary_crossentropy'])\n",
    "\n",
    "#%% Fit NN Model\n",
    "\n",
    "FitHist = BCNN.fit(XTrRsc,YTr,epochs=NEpochs,batch_size=BatchSize,verbose=1)\n",
    "print(\"Number of Epochs = \"+str(len(FitHist.history['binary_crossentropy'])))\n",
    "FitHist.history['binary_crossentropy'][-1]\n",
    "FitHist.history['binary_crossentropy'][-10:-1]\n",
    "\n",
    "#%% Make Predictions\n",
    "YHatTr = BCNN.predict(XTrRsc,batch_size=XTrRsc.shape[0]) # Note: Not scaled, so not necessary to undo.\n",
    "YHatTr = YHatTr.reshape((YHatTr.shape[0]),)\n",
    "\n",
    "YHatVal = BCNN.predict(XValRsc,batch_size=XValRsc.shape[0])\n",
    "YHatVal = YHatVal.reshape((YHatVal.shape[0]),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NN MODEL 2 Now try using softmax activation function\n",
    "\n",
    "#SetTheSeed(3456)\n",
    "NEpochs = 10 \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "\n",
    "BCNNsm = Sequential()\n",
    "\n",
    "BCNNsm.add(Dense(units=4,input_shape=(XTrRsc.shape[1],),activation=\"relu\",use_bias=True))\n",
    "BCNNsm.add(Dense(units=4,activation=\"relu\",use_bias=True))\n",
    "BCNNsm.add(Dense(units=4,activation=\"relu\",use_bias=True))\n",
    "BCNNsm.add(Dense(units=4,activation=\"relu\",use_bias=True))\n",
    "BCNNsm.add(Dense(units=2,activation=\"softmax\",use_bias=True))\n",
    "\n",
    "BCNNsm.compile(loss='categorical_crossentropy', optimizer=Optimizer,metrics=['categorical_crossentropy'])\n",
    "\n",
    "#%% Fit NN Model with Softmax\n",
    "\n",
    "# Need to make YTr an n by 2 matrix\n",
    "\n",
    "YTr = np.array([1-YTr,YTr]).transpose()\n",
    "\n",
    "FitHist = BCNNsm.fit(XTrRsc,YTr,epochs=NEpochs,batch_size=BatchSize,verbose=1)\n",
    "print(\"Number of Epochs = \"+str(len(FitHist.history['categorical_crossentropy'])))\n",
    "FitHist.history['categorical_crossentropy'][-1]\n",
    "FitHist.history['categorical_crossentropy'][-10:-1]\n",
    "\n",
    "#%% Make Predictions\n",
    "YHatTrSM = BCNNsm.predict(XTrRsc,batch_size=XTrRsc.shape[0]) # Note: Not scaled, so not necessary to undo.\n",
    "YHatValSM = BCNNsm.predict(XValRsc,batch_size=XValRsc.shape[0]) # Note: Not scaled, so not necessary to undo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict log-loss\n",
    "print(log_loss(y_val,YHatValSM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Hashing using 500 n_features\n",
    "\n",
    "#hashing for testing dataset\n",
    "y_test=test_000_04.iloc[:,2]\n",
    "X_test=test_000_04.iloc[:,feature]\n",
    "X_test_hash = X_test.copy()\n",
    "for i in range(X_test_hash.shape[1]):\n",
    "    X_test_hash.iloc[:,i]=X_test_hash.iloc[:,i].astype('str')\n",
    "h = FeatureHasher(n_features=500,input_type=\"string\")\n",
    "X_test_hash = h.transform(X_test_hash.values)\n",
    "\n",
    "#encoding hashing for training and validation sets\n",
    "h = FeatureHasher(n_features=500,input_type=\"string\")\n",
    "X_train_hash = h.transform(X_train_hash.values)\n",
    "X_val_hash = h.transform(X_val_hash.values)\n",
    "\n",
    "x_train_hash_copy=X_train_hash.copy()\n",
    "x_val_hash_copy=X_val_hash.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to array first \n",
    "x_train_hash_copy=x_train_hash_copy.toarray()\n",
    "x_val_hash_copy=x_val_hash_copy.toarray()\n",
    "x_test_hash_copy=X_test_hash.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get series data for LightGBM\n",
    "ytrain_series=pd.DataFrame(YTr).values\n",
    "xtrain_series=x_train_hash_copy.copy()\n",
    "\n",
    "xval_series=x_val_hash_copy.copy()\n",
    "yval_series=pd.DataFrame(YVal).values\n",
    "\n",
    "xtest_series=x_test_hash_copy.copy()\n",
    "ytest_series=pd.DataFrame(y_test).values\n",
    "\n",
    "#get series for y\n",
    "ytrain_series=ytrain_series[:,0]\n",
    "yval_series=yval_series[:,0]\n",
    "ytest_series=ytest_series[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling \n",
    "sc = StandardScaler()\n",
    "xtrain_series= sc.fit_transform(xtrain_series)\n",
    "xval_series=sc.fit_transform(xval_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = lightgbm.Dataset(xtrain_series, label=ytrain_series)\n",
    "test_data = lightgbm.Dataset(xval_series, label=yval_series,reference=train_data)\n",
    "\n",
    "# Train the model; parameter tuning manually\n",
    "\n",
    "parameters = {\n",
    "    'application': 'binary',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'is_unbalance': 'true',\n",
    "    'boosting': 'gbdt',\n",
    "    'num_leaves': 31,\n",
    "    'feature_fraction': 0.5,\n",
    "    'bagging_fraction': 0.5,\n",
    "    'bagging_freq': 8,\n",
    "    'learning_rate': 0.1,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "model = lightgbm.train(parameters,\n",
    "                       train_data,\n",
    "                       valid_sets=test_data,\n",
    "                       num_boost_round=100,\n",
    "                       early_stopping_rounds=100)\n",
    "#prediction\n",
    "y = model.predict(xval_series)\n",
    "\n",
    "#estimate log loss\n",
    "print(log_loss(y_val,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get generalized performance on testing dataset\n",
    "train_data = lightgbm.Dataset(xtrain_series, label=ytrain_series)\n",
    "test_data = lightgbm.Dataset(xtest_series, label=ytest_series,reference=train_data)\n",
    "\n",
    "model = lightgbm.train(parameters,\n",
    "                       train_data,\n",
    "                       valid_sets=test_data,\n",
    "                       num_boost_round=100,\n",
    "                       early_stopping_rounds=100)\n",
    "\n",
    "y = model.predict(xtest_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#estimate log loss\n",
    "print(log_loss(y_test,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T16:49:56.632985Z",
     "start_time": "2019-12-19T16:49:56.628996Z"
    }
   },
   "outputs": [],
   "source": [
    "#change working directory\n",
    "os.chdir('C:\\\\Users\\\\russe\\\\Desktop\\\\ML1\\\\final project\\\\Project Data\\\\Project Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T16:51:04.036821Z",
     "start_time": "2019-12-19T16:50:33.293672Z"
    }
   },
   "outputs": [],
   "source": [
    "#import testing dataset\n",
    "testing=pd.read_csv(\"ProjectTestData.csv\")\n",
    "#chage the hour variable\n",
    "testing.hour=testing.hour % 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T17:16:12.791706Z",
     "start_time": "2019-12-19T17:16:12.777176Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>hour</th>\n",
       "      <th>C1</th>\n",
       "      <th>banner_pos</th>\n",
       "      <th>site_id</th>\n",
       "      <th>site_domain</th>\n",
       "      <th>site_category</th>\n",
       "      <th>app_id</th>\n",
       "      <th>app_domain</th>\n",
       "      <th>app_category</th>\n",
       "      <th>...</th>\n",
       "      <th>device_type</th>\n",
       "      <th>device_conn_type</th>\n",
       "      <th>C14</th>\n",
       "      <th>C15</th>\n",
       "      <th>C16</th>\n",
       "      <th>C17</th>\n",
       "      <th>C18</th>\n",
       "      <th>C19</th>\n",
       "      <th>C20</th>\n",
       "      <th>C21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3295858251275419735</td>\n",
       "      <td>9</td>\n",
       "      <td>1005</td>\n",
       "      <td>1</td>\n",
       "      <td>85f751fd</td>\n",
       "      <td>c4e18dd6</td>\n",
       "      <td>50e219e0</td>\n",
       "      <td>1dc72b4d</td>\n",
       "      <td>2347f47a</td>\n",
       "      <td>0f2161f8</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8334</td>\n",
       "      <td>300</td>\n",
       "      <td>50</td>\n",
       "      <td>761</td>\n",
       "      <td>3</td>\n",
       "      <td>175</td>\n",
       "      <td>100075</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12281702837842634283</td>\n",
       "      <td>20</td>\n",
       "      <td>1007</td>\n",
       "      <td>0</td>\n",
       "      <td>85f751fd</td>\n",
       "      <td>c4e18dd6</td>\n",
       "      <td>50e219e0</td>\n",
       "      <td>8311368f</td>\n",
       "      <td>1dc9b529</td>\n",
       "      <td>0f2161f8</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>24303</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>2788</td>\n",
       "      <td>3</td>\n",
       "      <td>295</td>\n",
       "      <td>100194</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4638380339534007785</td>\n",
       "      <td>9</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>4e7614cf</td>\n",
       "      <td>c1aa3c04</td>\n",
       "      <td>f028772b</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>7801e8d9</td>\n",
       "      <td>07d7df22</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24165</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>2776</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>-1</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id  hour    C1  banner_pos   site_id site_domain  \\\n",
       "0   3295858251275419735     9  1005           1  85f751fd    c4e18dd6   \n",
       "1  12281702837842634283    20  1007           0  85f751fd    c4e18dd6   \n",
       "2   4638380339534007785     9  1005           0  4e7614cf    c1aa3c04   \n",
       "\n",
       "  site_category    app_id app_domain app_category  ... device_type  \\\n",
       "0      50e219e0  1dc72b4d   2347f47a     0f2161f8  ...           1   \n",
       "1      50e219e0  8311368f   1dc9b529     0f2161f8  ...           1   \n",
       "2      f028772b  ecad2386   7801e8d9     07d7df22  ...           1   \n",
       "\n",
       "  device_conn_type    C14  C15  C16   C17  C18  C19     C20  C21  \n",
       "0                0   8334  300   50   761    3  175  100075   23  \n",
       "1                2  24303  320   50  2788    3  295  100194  240  \n",
       "2                0  24165  320   50  2776    0   35      -1   79  \n",
       "\n",
       "[3 rows x 23 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T17:11:45.528864Z",
     "start_time": "2019-12-19T17:11:45.514907Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>click</th>\n",
       "      <th>hour</th>\n",
       "      <th>C1</th>\n",
       "      <th>banner_pos</th>\n",
       "      <th>site_id</th>\n",
       "      <th>site_domain</th>\n",
       "      <th>site_category</th>\n",
       "      <th>app_id</th>\n",
       "      <th>...</th>\n",
       "      <th>device_type</th>\n",
       "      <th>device_conn_type</th>\n",
       "      <th>C14</th>\n",
       "      <th>C15</th>\n",
       "      <th>C16</th>\n",
       "      <th>C17</th>\n",
       "      <th>C18</th>\n",
       "      <th>C19</th>\n",
       "      <th>C20</th>\n",
       "      <th>C21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>9650879390887470340</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1005</td>\n",
       "      <td>1</td>\n",
       "      <td>43d6df75</td>\n",
       "      <td>27e3c518</td>\n",
       "      <td>28905ebd</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>23143</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>2665</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>100233</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5966814300825754944</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1002</td>\n",
       "      <td>0</td>\n",
       "      <td>75f43c5a</td>\n",
       "      <td>c4e18dd6</td>\n",
       "      <td>50e219e0</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21153</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>2420</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>100221</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>509014319783936837</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>1005</td>\n",
       "      <td>1</td>\n",
       "      <td>e151e245</td>\n",
       "      <td>7e091613</td>\n",
       "      <td>f028772b</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17037</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>1934</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>-1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                   id  click  hour    C1  banner_pos   site_id  \\\n",
       "0           1  9650879390887470340      0    12  1005           1  43d6df75   \n",
       "1           2  5966814300825754944      1     9  1002           0  75f43c5a   \n",
       "2           3   509014319783936837      0    22  1005           1  e151e245   \n",
       "\n",
       "  site_domain site_category    app_id  ... device_type device_conn_type  \\\n",
       "0    27e3c518      28905ebd  ecad2386  ...           1                0   \n",
       "1    c4e18dd6      50e219e0  ecad2386  ...           0                0   \n",
       "2    7e091613      f028772b  ecad2386  ...           1                0   \n",
       "\n",
       "     C14  C15 C16   C17  C18  C19     C20  C21  \n",
       "0  23143  320  50  2665    0   35  100233  221  \n",
       "1  21153  320  50  2420    2   35  100221   69  \n",
       "2  17037  320  50  1934    2   39      -1   16  \n",
       "\n",
       "[3 rows x 25 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_000_01.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T16:52:11.861224Z",
     "start_time": "2019-12-19T16:52:09.374081Z"
    }
   },
   "outputs": [],
   "source": [
    "#import training data\n",
    "train_000_01=pd.read_csv(\"train_000_01.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T17:40:28.873406Z",
     "start_time": "2019-12-19T17:29:13.786114Z"
    }
   },
   "outputs": [],
   "source": [
    "#Define x-variables and y-variable in train and validation data set\n",
    "feature_test=range(1,23,1)\n",
    "X_train=train_000_01.iloc[:,feature]\n",
    "y_train=train_000_01.iloc[:,2]\n",
    "X_test=testing.iloc[:,feature_test]\n",
    "#y_val=val_000_01.iloc[:,2]\n",
    "#Feature Hashing\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "X_train_hash = X_train.copy()\n",
    "X_test_hash = X_test.copy()\n",
    "for i in range(X_train_hash.shape[1]):\n",
    "    X_train_hash.iloc[:,i]=X_train_hash.iloc[:,i].astype('str')\n",
    "for i in range(X_test_hash.shape[1]):\n",
    "    X_test_hash.iloc[:,i]=X_test_hash.iloc[:,i].astype('str')\n",
    "\n",
    "#encoding hashing\n",
    "h = FeatureHasher(n_features=10000,input_type=\"string\")\n",
    "X_train_hash = h.transform(X_train_hash.values)\n",
    "X_test_hash = h.transform(X_test_hash.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T18:10:54.898996Z",
     "start_time": "2019-12-19T18:05:50.376490Z"
    }
   },
   "outputs": [],
   "source": [
    "#fit the model\n",
    "l1 = LogisticRegression(penalty = 'l1', C = 0.1,random_state = 0)\n",
    "l1.fit(X_train_hash,y_train)\n",
    "y_pred_test = l1.predict_proba(X_test_hash)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T18:36:38.470283Z",
     "start_time": "2019-12-19T18:36:38.459337Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#write out the predict outcome\n",
    "df_predict = pd.DataFrame(y_pred_test)\n",
    "df_predict.to_csv('predict_outcome.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T18:47:01.545008Z",
     "start_time": "2019-12-19T18:46:58.759379Z"
    }
   },
   "outputs": [],
   "source": [
    "#write in the submission file\n",
    "submission=pd.read_csv(\"ProjectSubmission-TeamX.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T18:51:26.880719Z",
     "start_time": "2019-12-19T18:51:26.867755Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T18:50:49.080743Z",
     "start_time": "2019-12-19T18:50:48.451337Z"
    }
   },
   "outputs": [],
   "source": [
    "#insert the p(click) into submission file\n",
    "submission.iloc[:,1]=df_predict.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-19T18:52:38.333984Z",
     "start_time": "2019-12-19T18:51:56.415857Z"
    }
   },
   "outputs": [],
   "source": [
    "#write out the submission file with preidiction\n",
    "submission.to_csv('submission_final.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "291.389px",
    "left": "1363.19px",
    "right": "20px",
    "top": "15px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
